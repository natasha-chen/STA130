{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bee260d",
   "metadata": {},
   "source": [
    "Pre-lecture HW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2be431",
   "metadata": {},
   "source": [
    "Question 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280b0f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the URL\n",
    "url = \"https://raw.githubusercontent.com/KeithGalli/pandas/master/pokemon_data.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Get the count of missing values for each column\n",
    "missing_counts = df.isna().sum()\n",
    "\n",
    "# Output the missing values count\n",
    "print(missing_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171b1e0e",
   "metadata": {},
   "source": [
    "Question 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309d0a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset into a DataFrame\n",
    "url = \"https://raw.githubusercontent.com/KeithGalli/pandas/master/pokemon_data.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Get the shape of the DataFrame\n",
    "num_rows, num_columns = df.shape\n",
    "\n",
    "# Print the results\n",
    "print(f\"The dataset has {num_rows} rows and {num_columns} columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861d8796",
   "metadata": {},
   "source": [
    "\"observations\": characteristics of a data point represented by a row\n",
    "\"variables\": characteristics recorded of all observations represented by a column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb69afc1",
   "metadata": {},
   "source": [
    "Question 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114f81c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/KeithGalli/pandas/master/pokemon_data.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Descriptive statistics for numerical columns\n",
    "print(\"Descriptive Statistics for Numerical Columns:\\n\")\n",
    "print(df.describe())\n",
    "\n",
    "# Value counts for categorical columns like 'Type 1'\n",
    "print(\"\\nDistribution of Pokémon by Primary Type:\\n\")\n",
    "print(df['Type 1'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c774ca8",
   "metadata": {},
   "source": [
    "Question 4.\n",
    "\n",
    "The size of the dataset given by df.shape gives the total number of rows and columns, which in this case is 891 rows and 15 columns. df.describe() analyses only numerical values and thus does not count columns with non-numeric values. So, the output of a dataset with non-numeric columns will not be analyzed. \n",
    "\n",
    "As for the \"count\" values in df.describe(), they show the non-null enteries in every column, so the count might be lower than it actually is due to some columns containing missing values. df.shape, again, displays the total number in the \"count\" column. \n",
    "\n",
    "Overall, df.shape analyzes every column no matter the values it hold, while df.describe() only counts values that are numerical and non-null, leading to the discrepincies between the two in the \"count\" column. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256343ce",
   "metadata": {},
   "source": [
    "Question 5.\n",
    "\n",
    "\"attributes\": access characteristics of an object within the object. It does not compute anything since it is an existing value. For example, df.shape does not end in parenthesis and thus cannot take arguments. \n",
    "\n",
    "\"method\": a function that computes the data within the object that may need arguments inputed (which is why it has ()). It returns a new object or modifies the original one. \n",
    "\n",
    "Overall, attributes don't have () because they don't take arguments, and methods take arguments using ()."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05292ae",
   "metadata": {},
   "source": [
    "Post-lecture HW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ca9d39",
   "metadata": {},
   "source": [
    "Question 6.\n",
    "'count': number of non-missing values in the column \n",
    "'mean': the average of non-missing values\n",
    "'std': standard deviation of non-missing values\n",
    "'min': the minimum value in the column\n",
    "'25%': 25th percetile\n",
    "'50%': 50th percetile\n",
    "'75%': 75th percetile\n",
    "'max': the maximum value in the column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f63c7a",
   "metadata": {},
   "source": [
    "Question 7.\n",
    "1. While del df['col'] deletes a column from the dataframe permanently and cannot do the same for rows, df.dropna() removes rows and columns that contain missing values by returning a new dataframe without those rows/columns, but keeps the original dataframe. Thus, df.dropna() will be prefered if you need a data set with no missing values but want to keep the data set with missing values for future manipulations or because there are some values in it that are non-missing but still important. \n",
    "\n",
    "2. del df['col'] might be preferred over df.dropna() if the information in a column is redundant. You are able to chose the column you want to delete stright away. \n",
    "\n",
    "3. Applying del df['col'] before df.dropna() when both are used together could be important because del df['col'] allows you to delete all the information that you know is useless or information that you do not want to analyse. This deletion of rows will decrease the amount of data lost as opposed to using df.dropna() first, since the rows removed will not include the missing values from the deleted columns that del df['col'] took care of. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84d05c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/KeithGalli/pandas/master/pokemon_data.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Get the count of missing values for each column\n",
    "missing_counts = df.isna().sum()\n",
    "\n",
    "# Output the missing values count\n",
    "print(missing_counts)\n",
    "\n",
    "# Get the shape of the DataFrame and print original rows x columns\n",
    "num_rows, num_columns = df.shape\n",
    "print(f\"The dataset originally has {num_rows} rows and {num_columns} columns.\")\n",
    "\n",
    "# deleting a column\n",
    "del df['Type 2']\n",
    "print(df) # printing new dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44de6283",
   "metadata": {},
   "source": [
    "After recognizing that only one column contains any missing data, I decided to use del df['col'] since it could target that column to specifically delete it. Originally the data set was 800 rows x 12 columns, but now it is 800 rows x 11 columns. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91e845a",
   "metadata": {},
   "source": [
    "ChatGPT link:https://chatgpt.com/c/66ddfbd2-01cc-8007-8ad4-ea838530bb25 and summary: Here’s a brief summary of our entire conversation:\n",
    "\n",
    "Dataset Exploration:\n",
    "\n",
    "We discussed using the Pokémon and Titanic datasets, covering how to determine the size of a DataFrame using df.shape and how to summarize data with df.describe() and df['col'].value_counts().\n",
    "We explained the difference between attributes (e.g., df.shape) and methods (e.g., df.describe()).\n",
    "Handling Missing Data:\n",
    "\n",
    "We explored the use of df.dropna() to remove rows or columns with missing values (NaN), highlighting that it returns a new DataFrame unless inplace=True is specified.\n",
    "del df['col']:\n",
    "\n",
    "We examined how del df['col'] is used to permanently remove a column from the DataFrame.\n",
    "Order of Operations:\n",
    "\n",
    "We discussed the importance of applying del df['col'] before df.dropna() to avoid unintended row removal caused by irrelevant or heavily NaN-filled columns. This order ensures that data cleaning is efficient and doesn't accidentally discard important information.\n",
    "This summary covers key points about pandas operations, data exploration, and handling missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf78bb8",
   "metadata": {},
   "source": [
    "Question 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300d8aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#importing url\n",
    "url = \"https://raw.githubusercontent.com/KeithGalli/pandas/master/pokemon_data.csv\"\n",
    "\n",
    "df = pd.read_csv(url)\n",
    "grouped = df.groupby(\"Type 1\")[\"HP\"].describe()\n",
    "print(grouped)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8267db",
   "metadata": {},
   "source": [
    "1. This has grouped the same values from the column 'Type 1' and analysed the second column 'HP' in terms of the groups created in 'Type 1'. It then provides all the information for each group from 'Type 1' due to the describe() function. So, the above example shows the types of pokemon and how their HP is distributed. \n",
    "\n",
    "2. df.describe() only analyses non-missing values in each column. \n",
    "df.groupby(\"col1\")[\"col2\"].describe() shows the non-missing values for column 2 which has been grouped according to column 1. This can capture different values because the orginal data has been altered into a a new format.\n",
    "\n",
    "3. I personally think that chatgpt is easier to work with than google for troubleshooting errors because of how personalised it is. Google tends to have general answers that are somewhat hard to find due to the search engine and the keywords that it has to flip through, while chatbots like chatgpt immediately can spot and report the error, and even if it takes a couple tries, I still think it is way more efficient than clicking through all the sites that google believes to have the solution to my question. On top of that, speaking to chatgpt is similar to speaking to a person knowledgeable in everything, and it has a memory that can remember previous things mentioned in the conversation which can help with a more detailed explaination of why things went wrong. Chatbots also can take less specific questions, such as just copying the error code and pasting it into the chat when you are stuck and don't know how to formulate your question into words. Although sometimes if the inputed code is incorrect, chat will correct it without saying it is incorrect, and instead focus on expalin the function of the code, which can be a little misleading in terms of what is missing. \n",
    "Chatgpt link:https://chatgpt.com/c/66e1b471-2d20-8007-9474-b9dbe90f4c5c and summary: Here’s a brief summary of the code errors we addressed during this conversation:\n",
    "\n",
    "NameError: name 'pd' is not defined:\n",
    "\n",
    "Cause: The pandas library wasn't imported.\n",
    "Fix: Add import pandas as pd at the top of the script.\n",
    "FileNotFoundError: [Errno 2] No such file or directory: 'titanics.csv':\n",
    "\n",
    "Cause: The file 'titanics.csv' couldn't be found in the directory.\n",
    "Fix: Ensure the correct file path is used (either full or relative) and the file name is correct.\n",
    "DF.group_by(\"col1\")[\"col2\"].describe():\n",
    "\n",
    "Cause: There’s no method group_by() in pandas, the correct method is groupby().\n",
    "Fix: Use DF.groupby(\"col1\")[\"col2\"].describe().\n",
    "df.groupby(\"col1\")[\"col2\"].describle():\n",
    "\n",
    "Cause: describle() is not a valid pandas method, the correct method is describe().\n",
    "Fix: Use df.groupby(\"col1\")[\"col2\"].describe().\n",
    "titanic_df.groupby(sex)[\"age\"].describe():\n",
    "\n",
    "Cause: sex is treated as a variable instead of a string representing a column name.\n",
    "Fix: Use quotes around the column name: titanic_df.groupby(\"Sex\")[\"age\"].describe().\n",
    "titanic_df.groupby(\"sex\")[age].describe():\n",
    "\n",
    "Cause: age is not in quotes, so Python looks for a variable named age and raises an error.\n",
    "Fix: Use quotes around age to reference the column: titanic_df.groupby(\"Sex\")[\"age\"].describe().\n",
    "Each of these errors involved typos or incorrect usage of pandas syntax, which we corrected by ensuring proper import statements and correct references to column names."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b485e1d",
   "metadata": {},
   "source": [
    "Chatgpt link:https://chatgpt.com/c/66e0f0fa-4de4-8007-af1e-e4a5d2f9109e and summary: We discussed how to analyze the Titanic dataset, starting with the df.groupby(\"col1\")[\"col2\"].describe() function, which groups data by a column and provides descriptive statistics for another. We also explored how df.describe() summarizes columns in a DataFrame and how its count values reflect missing data. Finally, we covered differences between df.describe() for numerical and categorical data, and how missing values impact the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4159d069",
   "metadata": {},
   "source": [
    "Question 9. \n",
    "Mostly"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
